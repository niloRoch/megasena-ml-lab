# -*- coding: utf-8 -*-
"""
Modelo Mega-Sena - Machine Learning v2.0
Universo: 60 dezenas | Previs√£o: Top 10 n√∫meros mais prov√°veis
Features expandidas: Trincas, Pareto, Ciclos Avan√ßados, Comportamento, Sequ√™ncias
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.multioutput import MultiOutputClassifier
from scipy import stats
from scipy.stats import chi2_contingency
from google.colab import files
from itertools import combinations
import warnings
from collections import Counter, defaultdict, deque
warnings.filterwarnings('ignore')

# Upload do arquivo
print("Por favor, fa√ßa o upload do arquivo CSV da Mega-Sena")
uploaded = files.upload()
file_name = list(uploaded.keys())[0]

# Configura√ß√£o de visualiza√ß√£o
plt.style.use('seaborn-v0_8-darkgrid')
plt.rcParams['figure.figsize'] = (14, 10)
sns.set_palette("husl")

# Carregar dados
df = pd.read_csv(file_name, sep=';')
print(f"‚úÖ Dados carregados: {len(df)} concursos")
print(f"Colunas dispon√≠veis: {df.columns.tolist()}")

# Identificar colunas das bolas
ball_columns = [col for col in df.columns if 'Bola' in col or 'Dezena' in col or col.isdigit()]
if not ball_columns:
    ball_columns = [col for col in df.columns if df[col].dtype in ['int64', 'float64'] and df[col].between(1, 60).all()]

if len(ball_columns) < 6:
    print("‚ö†Ô∏è Aten√ß√£o: Por favor, ajuste as colunas das bolas manualmente")

balls = ball_columns[:6]
df_balls = df[balls].copy()

print(f"Colunas das bolas: {balls}")
print(f"Amostra dos dados:")
print(df_balls.head())

# ==================== FUN√á√ïES AUXILIARES ====================

def is_prime(n):
    """Verifica se n√∫mero √© primo"""
    if n <= 1:
        return False
    if n <= 3:
        return True
    if n % 2 == 0 or n % 3 == 0:
        return False
    i = 5
    while i * i <= n:
        if n % i == 0 or n % (i + 2) == 0:
            return False
        i += 6
    return True

def is_fibonacci(n):
    """Verifica se n√∫mero √© Fibonacci"""
    def is_perfect_square(x):
        s = int(np.sqrt(x))
        return s*s == x
    return is_perfect_square(5*n*n + 4) or is_perfect_square(5*n*n - 4)

def get_quadrante(num):
    """Divide volante 60 n√∫meros em 4 quadrantes"""
    if num <= 15:
        return 1
    elif num <= 30:
        return 2
    elif num <= 45:
        return 3
    else:
        return 4

def get_linha_coluna_megasena(num):
    """Posi√ß√£o no volante Mega-Sena (6x10 layout)"""
    linha = (num - 1) // 10 + 1
    coluna = (num - 1) % 10 + 1
    return linha, coluna

def get_zona(num):
    """Divide em 3 zonas: Baixa (1-20), M√©dia (21-40), Alta (41-60)"""
    if num <= 20:
        return 'baixa'
    elif num <= 40:
        return 'media'
    else:
        return 'alta'

def calculate_cycle_features(binary_series, current_idx):
    """Calcula features avan√ßadas de ciclos"""
    occurrences = binary_series[:current_idx]
    if occurrences.sum() == 0:
        return {
            'gap_atual': current_idx,
            'gap_medio': current_idx,
            'gap_std': 0,
            'gap_min': current_idx,
            'gap_max': current_idx,
            'ciclo_regular': 0,
            'prob_ciclo': 0,
            'tendencia_ciclo': 0,
            'aceleracao_ciclo': 0
        }

    indices = occurrences[occurrences == 1].index.tolist()
    
    gaps = []
    for i in range(len(indices) - 1):
        gaps.append(indices[i+1] - indices[i])

    if not gaps:
        gaps = [current_idx - indices[0]]

    gap_atual = current_idx - indices[-1] if indices else current_idx
    gap_medio = np.mean(gaps)
    gap_std = np.std(gaps) if len(gaps) > 1 else 0

    ciclo_regular = 1 / (1 + gap_std) if gap_std > 0 else 1
    prob_ciclo = 1 - (gap_atual / (gap_medio + gap_std + 1))
    prob_ciclo = max(0, min(1, prob_ciclo))

    # Tend√™ncia dos √∫ltimos 3 ciclos (est√° diminuindo ou aumentando?)
    tendencia_ciclo = 0
    if len(gaps) >= 3:
        ultimos_3 = gaps[-3:]
        tendencia_ciclo = (ultimos_3[-1] - ultimos_3[0]) / 3

    # Acelera√ß√£o (mudan√ßa na tend√™ncia)
    aceleracao_ciclo = 0
    if len(gaps) >= 4:
        ultimos_4 = gaps[-4:]
        aceleracao_ciclo = (ultimos_4[-1] - 2*ultimos_4[-2] + ultimos_4[-3])

    return {
        'gap_atual': gap_atual,
        'gap_medio': gap_medio,
        'gap_std': gap_std,
        'gap_min': min(gaps),
        'gap_max': max(gaps),
        'ciclo_regular': ciclo_regular,
        'prob_ciclo': prob_ciclo,
        'tendencia_ciclo': tendencia_ciclo,
        'aceleracao_ciclo': aceleracao_ciclo
    }

def calculate_momentum(binary_series, windows=[5, 10, 20]):
    """Calcula momentum (tend√™ncia) de apari√ß√µes"""
    momentum = {}
    for w in windows:
        recent = binary_series.tail(w).mean()
        overall = binary_series.mean()
        momentum[f'momentum_{w}'] = recent - overall
    return momentum

def calculate_behavioral_score(binary_series, current_idx, window=30):
    """
    Calcula score comportamental do n√∫mero
    - Consist√™ncia de apari√ß√µes
    - Padr√£o de distribui√ß√£o temporal
    - Volatilidade
    """
    if current_idx < window:
        window = current_idx
    
    recent = binary_series[current_idx-window:current_idx]
    
    # Volatilidade (qu√£o irregular s√£o as apari√ß√µes)
    volatilidade = recent.std()
    
    # Consist√™ncia (apari√ß√µes uniformemente distribu√≠das)
    indices_aparicoes = recent[recent == 1].index.tolist()
    if len(indices_aparicoes) > 1:
        intervalos = np.diff(indices_aparicoes)
        consistencia = 1 - (np.std(intervalos) / (np.mean(intervalos) + 1))
    else:
        consistencia = 0
    
    # Tend√™ncia recente (√∫ltimos 10 vs √∫ltimos 20)
    if current_idx >= 20:
        freq_10 = binary_series[current_idx-10:current_idx].mean()
        freq_20 = binary_series[current_idx-20:current_idx-10].mean()
        tendencia = freq_10 - freq_20
    else:
        tendencia = 0
    
    return {
        'volatilidade': volatilidade,
        'consistencia': consistencia,
        'tendencia_recente': tendencia
    }

# ==================== CONSTANTES ====================
primes = [n for n in range(1, 61) if is_prime(n)]
fibonacci_nums = [1, 1, 2, 3, 5, 8, 13, 21, 34, 55]
pares = [n for n in range(2, 61, 2)]
impares = [n for n in range(1, 61, 2)]
mult_3 = [n for n in range(3, 61, 3)]
mult_6 = [n for n in range(6, 61, 6)]
mult_9 = [n for n in range(9, 61, 9)]

print(f"\nüìä N√∫meros primos: {len(primes)} n√∫meros")
print(f"üìä N√∫meros Fibonacci: {fibonacci_nums}")
print(f"üìä Pares: {len(pares)} | √çmpares: {len(impares)}")
print(f"üìä M√∫ltiplos de 3: {len(mult_3)} | M√∫ltiplos de 6: {len(mult_6)} | M√∫ltiplos de 9: {len(mult_9)}")

# ==================== MATRIZ BIN√ÅRIA ====================
binary_matrix = pd.DataFrame(index=df.index, columns=range(1, 61), dtype=int)
for num in range(1, 61):
    binary_matrix[num] = df_balls.isin([num]).any(axis=1).astype(int)

print("\n‚úÖ Matriz bin√°ria criada (60 dezenas)")

# ==================== AN√ÅLISE DE TRINCAS CORRELACIONAIS ====================
print("\nüîç Analisando trincas correlacionais...")

trincas_freq = Counter()
for _, row in df_balls.iterrows():
    nums = sorted(row.values)
    for trinca in combinations(nums, 3):
        trincas_freq[trinca] += 1

# Top 20 trincas mais frequentes
top_trincas = trincas_freq.most_common(20)
print("\nTop 10 trincas mais frequentes:")
for i, (trinca, freq) in enumerate(top_trincas[:10], 1):
    print(f"  {i:2d}. {trinca}: {freq} vezes")

# Dicion√°rio de trincas por n√∫mero
trincas_por_numero = defaultdict(list)
for trinca, freq in trincas_freq.items():
    for num in trinca:
        trincas_por_numero[num].append((trinca, freq))

# Ordenar trincas de cada n√∫mero por frequ√™ncia
for num in trincas_por_numero:
    trincas_por_numero[num] = sorted(trincas_por_numero[num], key=lambda x: x[1], reverse=True)

# ==================== AN√ÅLISE DE PARES CORRELACIONAIS ====================
print("\nüîç Analisando pares correlacionais...")

pares_freq = Counter()
for _, row in df_balls.iterrows():
    nums = sorted(row.values)
    for par in combinations(nums, 2):
        pares_freq[par] += 1

top_pares = pares_freq.most_common(20)
print("\nTop 10 pares mais frequentes:")
for i, (par, freq) in enumerate(top_pares[:10], 1):
    print(f"  {i:2d}. {par}: {freq} vezes")

# Dicion√°rio de pares por n√∫mero
pares_por_numero = defaultdict(list)
for par, freq in pares_freq.items():
    for num in par:
        pares_por_numero[num].append((par, freq))

for num in pares_por_numero:
    pares_por_numero[num] = sorted(pares_por_numero[num], key=lambda x: x[1], reverse=True)

# ==================== ESTAT√çSTICAS B√ÅSICAS ====================
freq_abs = binary_matrix.sum()
freq_rel = freq_abs / len(df)
total_aparicoes = freq_abs.sum()

print("\n" + "="*60)
print("ESTAT√çSTICAS B√ÅSICAS")
print("="*60)
print(f"Total de apari√ß√µes: {total_aparicoes}")
print(f"M√©dia por dezena: {freq_abs.mean():.2f}")
print(f"Desvio padr√£o: {freq_abs.std():.2f}")
print(f"Dezena mais frequente: {freq_abs.idxmax()} ({freq_abs.max()} vezes)")
print(f"Dezena menos frequente: {freq_abs.idxmin()} ({freq_abs.min()} vezes)")

# ==================== AN√ÅLISE DE PARETO (80/20) ====================
print("\nüìä An√°lise de Pareto (Princ√≠pio 80/20)...")

freq_sorted = freq_abs.sort_values(ascending=False)
freq_cumsum = freq_sorted.cumsum()
freq_cumsum_pct = (freq_cumsum / freq_cumsum.max()) * 100

# Encontrar quantos n√∫meros representam 80% das apari√ß√µes
pareto_80_count = (freq_cumsum_pct <= 80).sum()
pareto_80_nums = freq_cumsum_pct[freq_cumsum_pct <= 80].index.tolist()

print(f"\nüéØ {pareto_80_count} n√∫meros representam 80% das apari√ß√µes:")
print(f"   {pareto_80_nums}")

# Classifica√ß√£o Pareto para cada n√∫mero
pareto_class = {}
for num in range(1, 61):
    if num in pareto_80_nums[:int(pareto_80_count * 0.5)]:
        pareto_class[num] = 'A'  # Top 50% do Pareto
    elif num in pareto_80_nums:
        pareto_class[num] = 'B'  # Restante do Pareto 80%
    else:
        pareto_class[num] = 'C'  # Fora do Pareto

# ==================== AN√ÅLISE DE SOMAS ====================
print("\n‚ûï Analisando padr√µes de somas...")

somas_historico = df_balls.sum(axis=1)
soma_media = somas_historico.mean()
soma_std = somas_historico.std()
soma_min = somas_historico.min()
soma_max = somas_historico.max()

print(f"Soma m√©dia: {soma_media:.1f}")
print(f"Desvio padr√£o: {soma_std:.1f}")
print(f"Intervalo: [{soma_min}, {soma_max}]")
print(f"Intervalo 1œÉ: [{soma_media-soma_std:.1f}, {soma_media+soma_std:.1f}]")
print(f"Intervalo 2œÉ: [{soma_media-2*soma_std:.1f}, {soma_media+2*soma_std:.1f}]")

# Distribui√ß√£o de somas por faixas
soma_bins = [0, 120, 150, 180, 210, 240, 300]
soma_labels = ['<120', '120-150', '150-180', '180-210', '210-240', '>240']
df['faixa_soma'] = pd.cut(somas_historico, bins=soma_bins, labels=soma_labels)
print("\nDistribui√ß√£o de somas:")
print(df['faixa_soma'].value_counts().sort_index())

# ==================== FEATURES EXPANDIDAS ====================
print("\nüîß Calculando features expandidas...")

# 1. ESTAT√çSTICAS B√ÅSICAS POR JOGO
df['soma'] = df_balls.sum(axis=1)
df['media'] = df_balls.mean(axis=1)
df['mediana'] = df_balls.median(axis=1)
df['std'] = df_balls.std(axis=1)
df['amplitude'] = df_balls.max(axis=1) - df_balls.min(axis=1)
df['q1'] = df_balls.quantile(0.25, axis=1)
df['q3'] = df_balls.quantile(0.75, axis=1)
df['iqr'] = df['q3'] - df['q1']

# 2. DISTRIBUI√á√ïES
df['pares'] = df_balls.apply(lambda x: sum(n % 2 == 0 for n in x), axis=1)
df['impares'] = 6 - df['pares']
df['primos'] = df_balls.apply(lambda x: sum(n in primes for n in x), axis=1)
df['fibonacci'] = df_balls.apply(lambda x: sum(n in fibonacci_nums for n in x), axis=1)

# 3. M√öLTIPLOS (incluindo 3, 6, 9)
for divisor in [2, 3, 4, 5, 6, 7, 8, 9, 10]:
    df[f'mult_{divisor}'] = df_balls.apply(lambda x: sum(n % divisor == 0 for n in x), axis=1)

# An√°lise espec√≠fica de m√∫ltiplos de 3, 6, 9
mult_3_historico = df['mult_3']
mult_6_historico = df['mult_6']
mult_9_historico = df['mult_9']

print(f"\nM√∫ltiplos de 3 - M√©dia: {mult_3_historico.mean():.2f}, Moda: {mult_3_historico.mode()[0]}")
print(f"M√∫ltiplos de 6 - M√©dia: {mult_6_historico.mean():.2f}, Moda: {mult_6_historico.mode()[0]}")
print(f"M√∫ltiplos de 9 - M√©dia: {mult_9_historico.mean():.2f}, Moda: {mult_9_historico.mode()[0]}")

# 4. QUADRANTES
for q in range(1, 5):
    df[f'quadrante_{q}'] = df_balls.apply(
        lambda x: sum(get_quadrante(n) == q for n in x), axis=1
    )

# 5. ZONAS
for zona in ['baixa', 'media', 'alta']:
    df[f'zona_{zona}'] = df_balls.apply(
        lambda x: sum(get_zona(n) == zona for n in x), axis=1
    )

# 6. POSI√á√ïES NO VOLANTE (linhas e colunas)
for linha in range(1, 7):
    df[f'linha_{linha}'] = df_balls.apply(
        lambda x: sum(get_linha_coluna_megasena(n)[0] == linha for n in x), axis=1
    )

linha_counts = {i: df[f'linha_{i}'].sum() for i in range(1, 7)}
print(f"\nDistribui√ß√£o hist√≥rica por linhas:")
for linha, count in linha_counts.items():
    print(f"  Linha {linha}: {count} n√∫meros ({count/total_aparicoes*100:.1f}%)")

for coluna in range(1, 11):
    df[f'coluna_{coluna}'] = df_balls.apply(
        lambda x: sum(get_linha_coluna_megasena(n)[1] == coluna for n in x), axis=1
    )

coluna_counts = {i: df[f'coluna_{i}'].sum() for i in range(1, 11)}
print(f"\nDistribui√ß√£o hist√≥rica por colunas:")
for coluna, count in coluna_counts.items():
    print(f"  Coluna {coluna}: {count} n√∫meros ({count/total_aparicoes*100:.1f}%)")

# 7. AN√ÅLISE DE SALTOS
def calculate_jump_features(row):
    sorted_nums = sorted(row)
    jumps = [sorted_nums[i+1] - sorted_nums[i] for i in range(len(sorted_nums)-1)]
    return {
        'salto_min': min(jumps),
        'salto_max': max(jumps),
        'salto_medio': np.mean(jumps),
        'salto_std': np.std(jumps),
        'saltos_1': sum(1 for j in jumps if j == 1),
        'saltos_2_5': sum(1 for j in jumps if 2 <= j <= 5),
        'saltos_grandes': sum(1 for j in jumps if j > 10)
    }

saltos_info = df_balls.apply(calculate_jump_features, axis=1)
for key in saltos_info[0].keys():
    df[key] = [info[key] for info in saltos_info]

# 8. SEQU√äNCIAS
df['sequencias'] = df_balls.apply(
    lambda x: sum(1 for i in range(len(sorted(x))-1) if sorted(x)[i+1] - sorted(x)[i] == 1),
    axis=1
)

sequencias_historico = df['sequencias']
print(f"\nSequ√™ncias - M√©dia: {sequencias_historico.mean():.2f}, Moda: {sequencias_historico.mode()[0]}")

# 9. PADR√ïES PAR-√çMPAR
def get_par_impar_pattern(row):
    sorted_nums = sorted(row)
    pattern = ''.join(['P' if n % 2 == 0 else 'I' for n in sorted_nums])
    return pattern

df['padrao_par_impar'] = df_balls.apply(get_par_impar_pattern, axis=1)

# 10. REPETI√á√ïES ENTRE CONCURSOS
repeticoes = []
for i in range(1, len(df_balls)):
    atual = set(df_balls.iloc[i])
    anterior = set(df_balls.iloc[i-1])
    repeticoes.append(len(atual & anterior))
df['repeticoes'] = [0] + repeticoes

# 11. DISTRIBUI√á√ÉO ESPACIAL
df['dist_espacial'] = df_balls.apply(
    lambda x: np.mean([sorted(x)[i+1] - sorted(x)[i] for i in range(5)]),
    axis=1
)

# 12. ASSIMETRIA E CURTOSE
df['assimetria'] = df_balls.apply(lambda x: stats.skew(x), axis=1)
df['curtose'] = df_balls.apply(lambda x: stats.kurtosis(x), axis=1)

# 13. CONCENTRA√á√ÉO
def calculate_concentration(row):
    sorted_nums = sorted(row)
    n = len(sorted_nums)
    cumsum = np.cumsum(sorted_nums)
    return (2 * np.sum((i+1) * val for i, val in enumerate(sorted_nums))) / (n * cumsum[-1]) - (n+1) / n

df['concentracao'] = df_balls.apply(calculate_concentration, axis=1)

print("‚úÖ Features calculadas com sucesso!")

# ==================== AN√ÅLISE DE CORRELA√á√ïES ====================
print("\nüìä Calculando correla√ß√µes entre dezenas...")
correlation_matrix = binary_matrix.corr()

corr_pairs = []
for i in range(1, 61):
    for j in range(i+1, 61):
        corr_pairs.append((i, j, correlation_matrix.loc[i, j]))

corr_pairs_sorted = sorted(corr_pairs, key=lambda x: abs(x[2]), reverse=True)
print("\nTop 10 pares mais correlacionados:")
for i, (n1, n2, corr) in enumerate(corr_pairs_sorted[:10], 1):
    print(f"  {i:2d}. {n1:2d}-{n2:2d}: {corr:.4f}")

# ==================== PREPARA√á√ÉO PARA MODELAGEM ====================
print("\nü§ñ Preparando dados para Machine Learning...")

X = []
y = []

for i in range(20, len(df)):  # Hist√≥rico m√≠nimo de 20 concursos
    features_concurso = []

    for num in range(1, 61):
        # 1. Features de ciclo (expandidas)
        cycle_features = calculate_cycle_features(binary_matrix[num], i)

        # 2. Features de frequ√™ncia
        freq_total = binary_matrix[num][:i].mean()
        freq_recent_5 = binary_matrix[num][i-5:i].mean()
        freq_recent_10 = binary_matrix[num][i-10:i].mean()
        freq_recent_20 = binary_matrix[num][i-20:i].mean()

        # 3. Momentum
        momentum_features = calculate_momentum(binary_matrix[num][:i], [5, 10, 20])

        # 4. Comportamento
        behavioral = calculate_behavioral_score(binary_matrix[num], i, window=30)

        # 5. Caracter√≠sticas est√°ticas
        is_par = 1 if num % 2 == 0 else 0
        is_prime_num = 1 if num in primes else 0
        is_fib = 1 if num in fibonacci_nums else 0
        quadrante = get_quadrante(num)
        linha, coluna = get_linha_coluna_megasena(num)
        zona_num = {'baixa': 1, 'media': 2, 'alta': 3}[get_zona(num)]

        # 6. M√∫ltiplos (incluindo 3, 6, 9)
        mult_features = [1 if num % d == 0 else 0 for d in [3, 5, 6, 7, 9]]

        # 7. Correla√ß√£o m√©dia
        avg_corr = correlation_matrix.iloc[num-1, :].mean()
        max_corr = correlation_matrix.iloc[num-1, :].max()

        # 8. Hot/Cold
        recent_avg = binary_matrix[num][max(0,i-30):i].mean()
        overall_avg = binary_matrix[num][:i].mean()
        hot_cold_score = recent_avg - overall_avg

        # 9. Pareto
        pareto_score = {'A': 3, 'B': 2, 'C': 1}[pareto_class[num]]

        # 10. Score de trincas (for√ßa das trincas que cont√™m este n√∫mero)
        if num in trincas_por_numero and len(trincas_por_numero[num]) > 0:
            top_trincas_num = trincas_por_numero[num][:5]
            trinca_score = sum(freq for _, freq in top_trincas_num) / len(top_trincas_num)
            trinca_max = top_trincas_num[0][1]
        else:
            trinca_score = 0
            trinca_max = 0

        # 11. Score de pares
        if num in pares_por_numero and len(pares_por_numero[num]) > 0:
            top_pares_num = pares_por_numero[num][:5]
            par_score = sum(freq for _, freq in top_pares_num) / len(top_pares_num)
            par_max = top_pares_num[0][1]
        else:
            par_score = 0
            par_max = 0

        # 12. Atraso normalizado
        atraso_norm = cycle_features['gap_atual'] / (cycle_features['gap_medio'] + 1)

        # 13. Tend√™ncia de linha/coluna
        linha_freq = binary_matrix[[n for n in range(1, 61) if get_linha_coluna_megasena(n)[0] == linha]][:i].sum().sum()
        coluna_freq = binary_matrix[[n for n in range(1, 61) if get_linha_coluna_megasena(n)[1] == coluna]][:i].sum().sum()
        linha_score = linha_freq / (i * 10)  # Normalizado
        coluna_score = coluna_freq / (i * 6)  # Normalizado

        # Adicionar features
        features_concurso.extend([
            # Frequ√™ncias (4)
            freq_total, freq_recent_5, freq_recent_10, freq_recent_20,
            # Ciclos expandidos (9)
            cycle_features['gap_atual'], cycle_features['gap_medio'],
            cycle_features['gap_std'], cycle_features['ciclo_regular'],
            cycle_features['prob_ciclo'], cycle_features['tendencia_ciclo'],
            cycle_features['aceleracao_ciclo'], atraso_norm,
            cycle_features['gap_max'] - cycle_features['gap_min'],  # Varia√ß√£o de gap
            # Momentum (3)
            momentum_features['momentum_5'], momentum_features['momentum_10'],
            momentum_features['momentum_20'],
            # Comportamento (3)
            behavioral['volatilidade'], behavioral['consistencia'],
            behavioral['tendencia_recente'],
            # Est√°ticas (7)
            is_par, is_prime_num, is_fib, quadrante, linha, coluna, zona_num,
            # M√∫ltiplos (5)
            *mult_features,
            # Correla√ß√£o (2)
            avg_corr, max_corr,
            # Hot/Cold (1)
            hot_cold_score,
            # Pareto (1)
            pareto_score,
            # Trincas e Pares (4)
            trinca_score, trinca_max, par_score, par_max,
            # Linha/Coluna tend√™ncia (2)
            linha_score, coluna_score
        ])

    X.append(features_concurso)
    y.append(binary_matrix.iloc[i, :].values)

X = np.array(X)
y = np.array(y)

num_features_per_number = len(features_concurso) // 60

print(f"‚úÖ Dataset preparado:")
print(f"   Amostras: {X.shape[0]}")
print(f"   Features por n√∫mero: {num_features_per_number}")
print(f"   Total de features: {X.shape[1]}")

# ==================== DIVIS√ÉO TREINO/TESTE ====================
test_size = 15
X_train, X_test = X[:-test_size], X[-test_size:]
y_train, y_test = y[:-test_size], y[-test_size:]

print(f"\nüìà Divis√£o dos dados:")
print(f"   Treino: {X_train.shape[0]} concursos")
print(f"   Teste: {X_test.shape[0]} concursos")

# Normaliza√ß√£o robusta
scaler = RobustScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# ==================== TREINAMENTO DOS MODELOS ====================
print("\n" + "="*60)
print("TREINAMENTO DOS MODELOS")
print("="*60)

# Modelo 1: Random Forest
print("\nüå≤ Random Forest...")
rf_model = RandomForestClassifier(
    n_estimators=600,
    max_depth=35,
    min_samples_split=4,
    min_samples_leaf=2,
    max_features='sqrt',
    random_state=42,
    n_jobs=-1,
    class_weight='balanced'
)
rf = MultiOutputClassifier(rf_model)
rf.fit(X_train_scaled, y_train)
rf_pred = rf.predict(X_test_scaled)

# Modelo 2: Gradient Boosting
print("üöÄ Gradient Boosting...")
gb_model = GradientBoostingClassifier(
    n_estimators=250,
    learning_rate=0.08,
    max_depth=12,
    min_samples_split=4,
    subsample=0.8,
    random_state=42
)
gb = MultiOutputClassifier(gb_model)
gb.fit(X_train_scaled, y_train)
gb_pred = gb.predict(X_test_scaled)

# Modelo 3: Logistic Regression
print("üìä Logistic Regression...")
lr_model = LogisticRegression(
    max_iter=8000,
    C=0.15,
    solver='saga',
    random_state=42,
    class_weight='balanced',
    n_jobs=-1
)
lr = MultiOutputClassifier(lr_model)
lr.fit(X_train_scaled, y_train)
lr_pred = lr.predict(X_test_scaled)

# ==================== AVALIA√á√ÉO ====================
def evaluate_model(y_true, y_pred, model_name):
    """Avalia modelo com m√©tricas espec√≠ficas para Mega-Sena"""
    print(f"\n{'='*60}")
    print(f"AVALIA√á√ÉO - {model_name.upper()}")
    print(f"{'='*60}")

    acertos_por_jogo = []
    for i in range(len(y_true)):
        true_nums = set(np.where(y_true[i] == 1)[0] + 1)
        pred_nums = set(np.where(y_pred[i] == 1)[0] + 1)
        acertos = len(true_nums & pred_nums)
        acertos_por_jogo.append(acertos)

        concurso_num = len(df) - test_size + i
        print(f"  Concurso {concurso_num}: {acertos}/6 acertos | "
              f"Previstos: {len(pred_nums)}")

    media_acertos = np.mean(acertos_por_jogo)
    print(f"\nüìä Estat√≠sticas:")
    print(f"   M√©dia de acertos: {media_acertos:.2f}/6")
    print(f"   M√≠nimo: {min(acertos_por_jogo)}/6")
    print(f"   M√°ximo: {max(acertos_por_jogo)}/6")
    print(f"   Desvio padr√£o: {np.std(acertos_por_jogo):.2f}")

    return {
        'acertos_medio': media_acertos,
        'acertos_lista': acertos_por_jogo
    }

# Avaliar todos os modelos
rf_metrics = evaluate_model(y_test, rf_pred, "Random Forest")
gb_metrics = evaluate_model(y_test, gb_pred, "Gradient Boosting")
lr_metrics = evaluate_model(y_test, lr_pred, "Logistic Regression")

# Selecionar melhor modelo
melhor_score = max(rf_metrics['acertos_medio'],
                   gb_metrics['acertos_medio'],
                   lr_metrics['acertos_medio'])

if rf_metrics['acertos_medio'] == melhor_score:
    best_model = rf
    best_name = "Random Forest"
elif gb_metrics['acertos_medio'] == melhor_score:
    best_model = gb
    best_name = "Gradient Boosting"
else:
    best_model = lr
    best_name = "Logistic Regression"

print(f"\nüèÜ Melhor modelo: {best_name}")

# ==================== PREVIS√ÉO PR√ìXIMO CONCURSO ====================
print("\n" + "="*60)
print(f"PREVIS√ÉO PARA O PR√ìXIMO CONCURSO ({len(df) + 1})")
print("="*60)

def predict_next_game_top10_advanced(model, scaler):
    """Prev√™ top 10 n√∫meros com an√°lise multi-crit√©rio"""
    next_features = []
    current_idx = len(df)

    for num in range(1, 61):
        # Calcular todas as features
        cycle_features = calculate_cycle_features(binary_matrix[num], current_idx)

        freq_total = binary_matrix[num].mean()
        freq_recent_5 = binary_matrix[num].tail(5).mean()
        freq_recent_10 = binary_matrix[num].tail(10).mean()
        freq_recent_20 = binary_matrix[num].tail(20).mean()

        momentum_features = calculate_momentum(binary_matrix[num], [5, 10, 20])
        behavioral = calculate_behavioral_score(binary_matrix[num], current_idx, window=30)

        is_par = 1 if num % 2 == 0 else 0
        is_prime_num = 1 if num in primes else 0
        is_fib = 1 if num in fibonacci_nums else 0
        quadrante = get_quadrante(num)
        linha, coluna = get_linha_coluna_megasena(num)
        zona_num = {'baixa': 1, 'media': 2, 'alta': 3}[get_zona(num)]

        mult_features = [1 if num % d == 0 else 0 for d in [3, 5, 6, 7, 9]]

        avg_corr = correlation_matrix.iloc[num-1, :].mean()
        max_corr = correlation_matrix.iloc[num-1, :].max()

        recent_avg = binary_matrix[num].tail(30).mean()
        overall_avg = binary_matrix[num].mean()
        hot_cold_score = recent_avg - overall_avg

        pareto_score = {'A': 3, 'B': 2, 'C': 1}[pareto_class[num]]

        if num in trincas_por_numero and len(trincas_por_numero[num]) > 0:
            top_trincas_num = trincas_por_numero[num][:5]
            trinca_score = sum(freq for _, freq in top_trincas_num) / len(top_trincas_num)
            trinca_max = top_trincas_num[0][1]
        else:
            trinca_score = 0
            trinca_max = 0

        if num in pares_por_numero and len(pares_por_numero[num]) > 0:
            top_pares_num = pares_por_numero[num][:5]
            par_score = sum(freq for _, freq in top_pares_num) / len(top_pares_num)
            par_max = top_pares_num[0][1]
        else:
            par_score = 0
            par_max = 0

        atraso_norm = cycle_features['gap_atual'] / (cycle_features['gap_medio'] + 1)

        linha_freq = binary_matrix[[n for n in range(1, 61) if get_linha_coluna_megasena(n)[0] == linha]].sum().sum()
        coluna_freq = binary_matrix[[n for n in range(1, 61) if get_linha_coluna_megasena(n)[1] == coluna]].sum().sum()
        linha_score = linha_freq / (current_idx * 10)
        coluna_score = coluna_freq / (current_idx * 6)

        next_features.extend([
            freq_total, freq_recent_5, freq_recent_10, freq_recent_20,
            cycle_features['gap_atual'], cycle_features['gap_medio'],
            cycle_features['gap_std'], cycle_features['ciclo_regular'],
            cycle_features['prob_ciclo'], cycle_features['tendencia_ciclo'],
            cycle_features['aceleracao_ciclo'], atraso_norm,
            cycle_features['gap_max'] - cycle_features['gap_min'],
            momentum_features['momentum_5'], momentum_features['momentum_10'],
            momentum_features['momentum_20'],
            behavioral['volatilidade'], behavioral['consistencia'],
            behavioral['tendencia_recente'],
            is_par, is_prime_num, is_fib, quadrante, linha, coluna, zona_num,
            *mult_features,
            avg_corr, max_corr,
            hot_cold_score,
            pareto_score,
            trinca_score, trinca_max, par_score, par_max,
            linha_score, coluna_score
        ])

    next_features = np.array([next_features])
    next_features_scaled = scaler.transform(next_features)

    # Obter probabilidades
    try:
        probabilities = []
        for estimator in model.estimators_:
            if hasattr(estimator, 'predict_proba'):
                prob = estimator.predict_proba(next_features_scaled)[0]
                probabilities.append(prob[1] if len(prob) > 1 else prob[0])
            else:
                probabilities.append(estimator.predict(next_features_scaled)[0])
        probabilities = np.array(probabilities)
    except:
        prediction = model.predict(next_features_scaled)[0]
        probabilities = prediction.astype(float)

    # Criar score combinado
    scores = {}
    for num in range(1, 61):
        idx = num - 1
        
        # Score do modelo ML
        ml_score = probabilities[idx]
        
        # Score de ciclo/atraso
        cycle_info = calculate_cycle_features(binary_matrix[num], current_idx)
        cycle_score = cycle_info['prob_ciclo'] * 0.3
        
        # Score de trincas
        if num in trincas_por_numero and len(trincas_por_numero[num]) > 0:
            trinca_strength = trincas_por_numero[num][0][1] / max(1, trincas_freq.most_common(1)[0][1])
        else:
            trinca_strength = 0
        
        # Score de pares
        if num in pares_por_numero and len(pares_por_numero[num]) > 0:
            par_strength = pares_por_numero[num][0][1] / max(1, pares_freq.most_common(1)[0][1])
        else:
            par_strength = 0
        
        # Score Pareto
        pareto_bonus = {'A': 0.2, 'B': 0.1, 'C': 0}[pareto_class[num]]
        
        # Score combinado
        combined_score = (
            ml_score * 0.5 +
            cycle_score * 0.2 +
            trinca_strength * 0.15 +
            par_strength * 0.1 +
            pareto_bonus * 0.05
        )
        
        scores[num] = combined_score

    # Selecionar top 10
    top_10_sorted = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:10]
    top_10_numbers = sorted([num for num, _ in top_10_sorted])
    top_10_scores = [scores[num] for num in top_10_numbers]

    return top_10_numbers, top_10_scores, probabilities, scores

# Fazer previs√£o
predicted_top10, predicted_scores, all_probs, all_scores = predict_next_game_top10_advanced(best_model, scaler)

print(f"\nüéØ TOP 10 DEZENAS MAIS PROV√ÅVEIS:")
print(f"   {predicted_top10}")

print(f"\nScores individuais:")
for num in predicted_top10:
    print(f"   {num:2d}: {all_scores[num]:.4f}")

# ==================== AN√ÅLISE DETALHADA DA PREVIS√ÉO ====================
print(f"\n" + "="*60)
print("AN√ÅLISE DETALHADA DA PREVIS√ÉO")
print("="*60)

# An√°lise b√°sica
pred_pares = sum(1 for n in predicted_top10 if n % 2 == 0)
pred_impares = 10 - pred_pares
pred_primos = sum(1 for n in predicted_top10 if n in primes)
pred_mult_3 = sum(1 for n in predicted_top10 if n % 3 == 0)
pred_mult_6 = sum(1 for n in predicted_top10 if n % 6 == 0)
pred_mult_9 = sum(1 for n in predicted_top10 if n % 9 == 0)

print(f"\nüìä Composi√ß√£o:")
print(f"   Pares: {pred_pares} | √çmpares: {pred_impares}")
print(f"   Primos: {pred_primos}")
print(f"   M√∫ltiplos de 3: {pred_mult_3} | de 6: {pred_mult_6} | de 9: {pred_mult_9}")
print(f"   Soma: {sum(predicted_top10)}")
print(f"   M√©dia: {np.mean(predicted_top10):.1f}")

# Distribui√ß√£o por quadrantes
print(f"\nüìç Distribui√ß√£o por Quadrantes:")
for q in range(1, 5):
    nums_q = [n for n in predicted_top10 if get_quadrante(n) == q]
    faixa = f"{(q-1)*15+1}-{q*15}"
    print(f"   Q{q} ({faixa}): {len(nums_q)} n√∫meros {nums_q if nums_q else '-'}")

# Distribui√ß√£o por zonas
print(f"\nüå°Ô∏è Distribui√ß√£o por Zonas:")
for zona in ['baixa', 'media', 'alta']:
    nums_zona = [n for n in predicted_top10 if get_zona(n) == zona]
    print(f"   {zona.capitalize()}: {len(nums_zona)} n√∫meros {nums_zona if nums_zona else '-'}")

# Distribui√ß√£o por linhas
print(f"\nüìè Distribui√ß√£o por Linhas (volante 6x10):")
for linha in range(1, 7):
    nums_linha = [n for n in predicted_top10 if get_linha_coluna_megasena(n)[0] == linha]
    print(f"   Linha {linha}: {len(nums_linha)} n√∫meros {nums_linha if nums_linha else '-'}")

# Distribui√ß√£o por colunas
print(f"\nüìê Distribui√ß√£o por Colunas:")
for coluna in range(1, 11):
    nums_coluna = [n for n in predicted_top10 if get_linha_coluna_megasena(n)[1] == coluna]
    if nums_coluna:
        print(f"   Coluna {coluna}: {len(nums_coluna)} n√∫meros {nums_coluna}")

# Sequ√™ncias
pred_sorted = sorted(predicted_top10)
pred_sequencias = sum(1 for i in range(len(pred_sorted)-1) if pred_sorted[i+1] - pred_sorted[i] == 1)
print(f"\nüî¢ Sequ√™ncias consecutivas: {pred_sequencias}")

# Saltos
saltos = [pred_sorted[i+1] - pred_sorted[i] for i in range(len(pred_sorted)-1)]
print(f"   Salto m√©dio: {np.mean(saltos):.1f}")
print(f"   Salto m√≠nimo: {min(saltos)}")
print(f"   Salto m√°ximo: {max(saltos)}")

# N√∫meros atrasados
print(f"\n‚è∞ AN√ÅLISE DE ATRASOS:")
gaps_atuais = {}
for num in range(1, 61):
    if binary_matrix[num].any():
        last_idx = binary_matrix[num][::-1].idxmax()
        gaps_atuais[num] = len(binary_matrix) - last_idx
    else:
        gaps_atuais[num] = len(binary_matrix)

nums_atrasados = sorted(gaps_atuais.items(), key=lambda x: x[1], reverse=True)[:20]

print(f"\nTop 20 n√∫meros mais atrasados:")
for i, (num, gap) in enumerate(nums_atrasados, 1):
    marcador = "‚≠ê" if num in predicted_top10 else "  "
    pareto_mark = f"[{pareto_class[num]}]"
    print(f"   {i:2d}. {marcador} {pareto_mark} Dezena {num:2d}: {gap:3d} concursos")

# An√°lise de trincas previstas
print(f"\nüîó TRINCAS PRESENTES NA PREVIS√ÉO:")
trincas_previstas = list(combinations(predicted_top10, 3))
trincas_previstas_freq = [(t, trincas_freq.get(t, 0)) for t in trincas_previstas]
trincas_previstas_freq.sort(key=lambda x: x[1], reverse=True)

print(f"   Top 5 trincas hist√≥ricas presentes:")
for i, (trinca, freq) in enumerate(trincas_previstas_freq[:5], 1):
    if freq > 0:
        print(f"      {i}. {trinca}: {freq} vezes")

# An√°lise de pares previstos
print(f"\nüë• PARES PRESENTES NA PREVIS√ÉO:")
pares_previstos = list(combinations(predicted_top10, 2))
pares_previstos_freq = [(p, pares_freq.get(p, 0)) for p in pares_previstos]
pares_previstos_freq.sort(key=lambda x: x[1], reverse=True)

print(f"   Top 5 pares hist√≥ricos presentes:")
for i, (par, freq) in enumerate(pares_previstos_freq[:5], 1):
    if freq > 0:
        print(f"      {i}. {par}: {freq} vezes")

# Classifica√ß√£o Pareto
pareto_distribution = Counter(pareto_class[n] for n in predicted_top10)
print(f"\nüìä Distribui√ß√£o Pareto:")
print(f"   Classe A (top performers): {pareto_distribution.get('A', 0)} n√∫meros")
print(f"   Classe B (m√©dio): {pareto_distribution.get('B', 0)} n√∫meros")
print(f"   Classe C (baixo): {pareto_distribution.get('C', 0)} n√∫meros")

# Valida√ß√£o com padr√µes hist√≥ricos
print(f"\n‚úÖ VALIDA√á√ÉO COM PADR√ïES HIST√ìRICOS:")
print(f"   Soma da previs√£o: {sum(predicted_top10)} (hist√≥rico: {soma_media:.0f} ¬± {soma_std:.0f})")
print(f"   Pares/√çmpares: {pred_pares}/{pred_impares} (moda hist√≥rica: {df['pares'].mode()[0]}/{6-df['pares'].mode()[0]})")
print(f"   M√∫ltiplos de 3: {pred_mult_3} (m√©dia hist√≥rica: {mult_3_historico.mean():.1f})")
print(f"   Sequ√™ncias: {pred_sequencias} (moda hist√≥rica: {sequencias_historico.mode()[0]})")

print(f"\n" + "="*60)
print(f"üí° SUGEST√ïES DE JOGOS ")
print(f"="*60)

# Sugest√£o 1: Balanceado
print(f"\n1Ô∏è‚É£ JOGO BALANCEADO (3 pares, 3 √≠mpares):")
pares_top10 = [n for n in predicted_top10 if n % 2 == 0]
impares_top10 = [n for n in predicted_top10 if n % 2 != 0]
if len(pares_top10) >= 3 and len(impares_top10) >= 3:
    jogo1 = sorted(pares_top10[:3] + impares_top10[:3])
    print(f"   {jogo1}")
else:
    print(f"   N√£o h√° combina√ß√£o 3-3 dispon√≠vel")

# Sugest√£o 2: Baseado em atrasos
print(f"\n2Ô∏è‚É£ JOGO COM N√öMEROS ATRASADOS:")
nums_atrasados_top10 = [n for n, _ in nums_atrasados if n in predicted_top10][:6]
if len(nums_atrasados_top10) >= 6:
    print(f"   {sorted(nums_atrasados_top10)}")
else:
    print(f"   N√∫meros dispon√≠veis: {sorted(nums_atrasados_top10)}")

# Sugest√£o 3: Baseado em Pareto A
print(f"\n3Ô∏è‚É£ JOGO FOCADO EM PARETO CLASSE A:")
pareto_a_nums = [n for n in predicted_top10 if pareto_class[n] == 'A']
if len(pareto_a_nums) >= 4:
    outros = [n for n in predicted_top10 if pareto_class[n] != 'A'][:2]
    jogo3 = sorted(pareto_a_nums[:4] + outros)
    print(f"   {jogo3}")
else:
    print(f"   N√∫meros Pareto A dispon√≠veis: {sorted(pareto_a_nums)}")

print(f"\nFaz Teu nome!!!")
